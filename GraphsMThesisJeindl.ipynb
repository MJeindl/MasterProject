{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from scipy import constants as const\n",
    "plt.rcParams['text.usetex'] = True\n",
    "\n",
    "#Sellmeier equation\n",
    "def n_squared(lamb, coeffs):\n",
    "    '''lamb in µm'''\n",
    "    n2 = 1\n",
    "    lsquare = lamb**2\n",
    "    for index in range(3):\n",
    "        n2 = n2 + coeffs[index, 0]*lsquare/(lsquare-coeffs[index, 1]**2)\n",
    "    return n2\n",
    "\n",
    "#Lensmaker equation\n",
    "def lensmaker(n, R1, R2, d=0):\n",
    "    '''Returns 1/focal length'''\n",
    "    f_inv = (n-1)*(1/R1 - 1/R2 + (n-1)*d/(n*R1*R2))\n",
    "    return f_inv\n",
    "\n",
    "def wavToEnergy(lamb):\n",
    "    #Energy in eV, lamb in nm\n",
    "    return const.h*const.c/lamb*1e9/const.elementary_charge\n",
    "\n",
    "def energyToWav(E):\n",
    "    #Energy in eV, lamb in nm\n",
    "    return const.h*const.c/E*1e9/const.elementary_charge\n",
    "\n",
    "\n",
    "\n",
    "#https://refractiveindex.info/?shelf=glass&book=fused_silica&page=Malitson\n",
    "#Maltison 1965 UV fused silica: 0.21 µm - 3.71 µm\n",
    "coeffsUVFS = np.array([[0.6961663, 0.0684043], [0.4079426, 0.1162414], [0.8974794, 9.896161]])\n",
    "\n",
    "#Energy range is 1.3 eV to 5 eV in .1 eV steps\n",
    "energies = np.linspace(1.3, 5, 37)*const.elementary_charge\n",
    "wavs = const.h*const.c/energies\n",
    "\n",
    "\n",
    "fig1, axs1 = plt.subplots(1,1, layout='constrained', figsize = (6,4), dpi=200)\n",
    "fig2, axs2 = plt.subplots(1,1, layout='constrained', figsize = (6,4), dpi=200)\n",
    "#µm for sellmeier\n",
    "n_wav = np.sqrt(n_squared(wavs*1e6, coeffsUVFS))\n",
    "axs1.plot(wavs*1e9, n_wav)\n",
    "axs1.set_ylabel('n / 1')\n",
    "axs1.set_xlabel(r'$\\lambda$ / nm')\n",
    "axs1.set_xticks(np.arange(250, 951, 100))\n",
    "secax0 = axs1.secondary_xaxis('top', functions=(wavToEnergy, energyToWav))\n",
    "secax0.set_xticks([1.5, 2, 3, 4, 5])\n",
    "secax0.set_xlabel(\"E / eV\")\n",
    "\n",
    "#second part with focal distance\n",
    "focal_distance = lensmaker(n_wav, np.inf, 59.4)\n",
    "focal_distance = 1/focal_distance\n",
    "axs2.plot(wavs*1e9, -focal_distance)\n",
    "axs2.set_ylabel('f / mm')\n",
    "axs2.set_xlabel(r'$\\lambda$ / nm')\n",
    "axs2.set_xticks(np.arange(250, 951, 100))\n",
    "\n",
    "secax1 = axs2.secondary_xaxis('top', functions=(wavToEnergy, energyToWav))\n",
    "secax1.set_xticks([1.5, 2, 3, 4, 5])\n",
    "secax1.set_xlabel(\"E / eV\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#taken from edmund optics: Laser Optics and Resource Guide Section 2: Gaussian Beam Propagation\n",
    "\n",
    "w_c = lambda w0, lamb, z: w0*np.sqrt(1+(lamb*z/(np.pi*w0**2))**2)\n",
    "w0_c = lambda lamb, theta: lamb/np.pi/theta\n",
    "zr_c = lambda lamb, w0: np.pi*w0**2/lamb\n",
    "\n",
    "#collimated beam through lens with focal distance f\n",
    "#taken from angular aperture\n",
    "theta_c = lambda D, f: np.arctan(D/(2*f))\n",
    "\n",
    "\n",
    "\n",
    "wav = 653e-9 # nm\n",
    "#https://refractiveindex.info/?shelf=glass&book=fused_silica&page=Malitson\n",
    "#Maltison 1965 UV fused silica: 0.21 µm - 3.71 µm\n",
    "coeffsUVFS = np.array([[0.6961663, 0.0684043], [0.4079426, 0.1162414], [0.8974794, 9.896161]])\n",
    "n = np.sqrt(n_squared(wav*1e6,coeffsUVFS))\n",
    "f = 1/lensmaker(n, 59.4, np.inf)*1e-3\n",
    "\n",
    "diameters = np.array([1, 2, 3, 4])*1e-3 # mm\n",
    "thet = theta_c(diameters, f)\n",
    "w0 = w0_c(wav, thet)\n",
    "#print(w0*2)\n",
    "\n",
    "zr = zr_c(wav, w0[1])\n",
    "\n",
    "z = np.linspace(-1e-3, zr/2, 200)\n",
    "\n",
    "plt.figure()\n",
    "#plt.tight_layout()\n",
    "fig1, axs1 = plt.subplots(1,1, layout='constrained', figsize = (6,4), dpi=200)\n",
    "fig2, axs2 = plt.subplots(1,1, layout='constrained', figsize = (6,4), dpi=200)\n",
    "#fig.suptitle(\"653 nm beam waist\")\n",
    "for index in range(len(diameters)):\n",
    "    axs1.plot(z*1e3, w_c(w0[index], wav, z)*2e6, label=\"%.1f mm\" %(diameters[index]*1e3))\n",
    "axs1.set_xlabel(\"z / mm\")\n",
    "axs1.set_ylabel(\"beam waist / µm\")\n",
    "axs1.legend()\n",
    "\n",
    "z = np.linspace(-2e-4, zr/4, 200)\n",
    "\n",
    "\n",
    "for index in range(len(diameters)):\n",
    "    axs2.plot(z*1e3, 1/(w_c(w0[index], wav, z)/w0[index])**2, label=\"%.1f mm\" %(diameters[index]*1e3))\n",
    "axs2.set_xlabel(\"z / mm\")\n",
    "axs2.set_ylabel(\"relative maximum intensity / a.u.\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#taken from edmund optics: Laser Optics and Resource Guide Section 2: Gaussian Beam Propagation\n",
    "\n",
    "w_c = lambda w0, lamb, z: w0*np.sqrt(1+(lamb*z/(np.pi*w0**2))**2)\n",
    "w0_c = lambda lamb, theta: lamb/np.pi/theta\n",
    "zr_c = lambda lamb, w0: np.pi*w0**2/lamb\n",
    "\n",
    "#collimated beam through lens with focal distance f\n",
    "#taken from angular aperture\n",
    "theta_c = lambda D, f: np.arctan(D/(2*f))\n",
    "\n",
    "\n",
    "dia = 2.5e-3 # m\n",
    "wavs = np.array([250,300, 400, 500, 600, 700, 800, 900])*1e-9 #wavs in m\n",
    "n = np.sqrt(n_squared(wav*1e6,coeffsUVFS))\n",
    "f = 1/lensmaker(n, 59.4, np.inf)*1e-3\n",
    "thet = theta_c(dia, f)\n",
    "w0 = w0_c(wavs, thet)\n",
    "\n",
    "zr = np.max(zr_c(wavs, w0))\n",
    "\n",
    "z = np.linspace(-2e-4, zr/4, 200)\n",
    "\n",
    "plt.figure()\n",
    "fig1, axs1 = plt.subplots(1,1, layout='constrained', figsize = (6,4), dpi=200)\n",
    "#plt.title(\"Beam waist vs wavelength behavior at 2 mm collimated waist\")\n",
    "for index in range(len(wavs)):\n",
    "    axs1.plot(z*1e3, w_c(w0[index], wavs[index], z)*2e6, label=\"%.1f nm\" %(wavs[index]*1e9))\n",
    "axs1.set_xlabel(\"z / mm\")\n",
    "axs1.set_ylabel(\"beam waist / µm\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['text.usetex'] = True\n",
    "\n",
    "def gaussian(x, sig = 1, mu = 0):\n",
    "    return 1/(np.sqrt(2*np.pi)*sig)*np.exp(-(x-mu)**2/(2*sig**2))\n",
    "\n",
    "def gaussProd(x, sig1, sig2, mu1, mu2):\n",
    "    mu_n = (mu1*sig2**2 + mu2*sig1**2)/(sig1**2 + sig2**2)\n",
    "    sig_n = sig1*sig2/np.sqrt(sig1**2 + sig2**2)\n",
    "    return 1/(np.sqrt(2*np.pi)*sig_n)*np.exp(-(x-mu_n)**2/(2*sig_n**2))\n",
    "\n",
    "def cFactor(sigPump, sig2, mu1, mu2):\n",
    "    return np.sqrt((sigPump**2 + sig2**2)/sigPump**2)*np.exp((mu1-mu2)**2/(2*(sigPump**2+sig2**2)))\n",
    "\n",
    "\n",
    "\n",
    "def plotVisGaussians(x, sig2, dmu):\n",
    "    plt.figure()\n",
    "    #probe\n",
    "    plt.plot(x, gaussian(x, 1, -dmu/2), label = r\"probe: $\\sigma$ = 1; $\\mu = %.1f$\" %(-dmu/2))\n",
    "    #pump\n",
    "    plt.plot(x, gaussian(x, 2, +dmu/2), label = r\"pump: $\\sigma$ = %d; $\\mu = %.1f$\" %(sig2, dmu/2))\n",
    "    #overlap\n",
    "    plt.plot(x, gaussProd(x, 1, sig2, -dmu/2, dmu/2), \"r--\", label = r\"overlap\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(r\"x / $\\sigma$\")\n",
    "    plt.ylabel(r\"I / a.u.\")\n",
    "    plt.title(r\"C = %.2e\" %(cFactor(sig2, 1, dmu,0)))\n",
    "    plt.show()\n",
    "\n",
    "#case 1 µ1 = µ2, sig 1 >> sig 2\n",
    "#\n",
    "sig2 = 1 #times sig 1; sig2 is pump\n",
    "dmu = 0 \n",
    "\n",
    "x = np.linspace(-3, 3, 200)\n",
    "plotVisGaussians(x, sig2, dmu)\n",
    "\n",
    "sig2 = 2 #times sig 1\n",
    "dmu = 0 \n",
    "\n",
    "plotVisGaussians(x, sig2, dmu)\n",
    "\n",
    "sig2 = 1\n",
    "dmu = 2*np.sqrt(2*np.log(2))*sig2 #FWHM as distance\n",
    "plotVisGaussians(x, sig2, dmu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['text.usetex'] = True\n",
    "\n",
    "def gaussian(x, sig = 1, mu = 0):\n",
    "    return 1/(np.sqrt(2*np.pi)*sig)*np.exp(-(x-mu)**2/(2*sig**2))\n",
    "\n",
    "def gaussProd(x, sig1, sig2, mu1, mu2):\n",
    "    mu_n = (mu1*sig2**2 + mu2*sig1**2)/(sig1**2 + sig2**2)\n",
    "    sig_n = sig1*sig2/np.sqrt(sig1**2 + sig2**2)\n",
    "    return 1/(np.sqrt(2*np.pi)*sig_n)*np.exp(-(x-mu_n)**2/(2*sig_n**2))\n",
    "\n",
    "def cFactor(sigPump, sig2, mu1, mu2):\n",
    "    return np.sqrt((sigPump**2 + sig2**2)/sigPump**2)*np.exp((mu1-mu2)**2/(2*(sigPump**2+sig2**2)))\n",
    "\n",
    "\n",
    "\n",
    "def plotVisGaussians(x, sig2, dmu):\n",
    "    plt.figure()\n",
    "    #probe\n",
    "    plt.plot(x, gaussian(x, 1, -dmu/2), label = r\"probe: $\\sigma$ = 1; $\\mu = %.1f$\" %(-dmu/2))\n",
    "    #pump\n",
    "    plt.plot(x, gaussian(x, 2, +dmu/2), label = r\"pump: $\\sigma$ = %d; $\\mu = %.1f$\" %(sig2, dmu/2))\n",
    "    #overlap\n",
    "    plt.plot(x, gaussProd(x, 1, sig2, -dmu/2, dmu/2), \"r--\", label = r\"overlap\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(r\"x / $\\sigma$\")\n",
    "    plt.ylabel(r\"I / a.u.\")\n",
    "    plt.title(r\"C = %.2e\" %(cFactor(sig2, 1, dmu,0)))\n",
    "    plt.show()\n",
    "\n",
    "def plotCompareGaussians(x, sigPump, dmu_vec):\n",
    "    fig = plt.figure()\n",
    "    #plot pump gaussian\n",
    "    plt.plot(x, gaussian(x, sigPump, 0))\n",
    "    for ind in range(len(dmu_vec)):\n",
    "        plt.plot(x, gaussian(x, 1, dmu_vec[ind]), label=\"C = %.3f\" %cFactor(sigPump, 1, 0, dmu_vec[ind]))\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    fig.clear()\n",
    "\n",
    "#case 1 µ1 = µ2, sig 1 >> sig 2\n",
    "#\n",
    "sig2 = 3 #times sig 1; sig2 is pump\n",
    "dmu = 0 \n",
    "\n",
    "x = np.linspace(-3, 3, 200)\n",
    "dmu = [0, 0.1, 0.3, 0.5]\n",
    "sigPump = 3\n",
    "plotCompareGaussians(x, sigPump, dmu*sigPump)\n",
    "sigPump = 2\n",
    "plotCompareGaussians(x, sigPump, dmu*sigPump)\n",
    "sigPump = 1\n",
    "plotCompareGaussians(x, sigPump, dmu*sigPump)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test binning of numerical correction factor\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "def gaussian(x, sig = 1, mu = 0):\n",
    "    return 1/(np.sqrt(2*np.pi)*sig)*np.exp(-(x-mu)**2/(2*sig**2))\n",
    "\n",
    "def cFactor(sigPump, sig2, mu1, mu2):\n",
    "    return np.sqrt((sigPump**2 + sig2**2)/sigPump**2)*np.exp((mu1-mu2)**2/(2*(sigPump**2+sig2**2)))\n",
    "\n",
    "def binMap(map, xBinning, yBinning=0):\n",
    "    '''N_binning means that N*N pixels are binned together\\n\n",
    "    only takes square z*z maps'''\n",
    "    if yBinning == 0:\n",
    "        yBinning = xBinning\n",
    "    xBins = int(np.shape(map)[0]//xBinning) #along one axis\n",
    "    yBins = int(np.shape(map)[1]//yBinning) #along one axis\n",
    "    outmap = map.reshape(xBins, xBinning, yBins, yBinning).sum(3).sum(1)\n",
    "    return outmap\n",
    "\n",
    "\n",
    "#using identical gaussians for this\n",
    "points_per_sig = 1024 #starting value 1000 points for 1 sig distance\n",
    "sig = 1 #does not matter since I do binning in steps of sig at first\n",
    "mu = 0\n",
    "###----analytical cFactor ----###\n",
    "cFactorAnalytic = cFactor(sig, sig, mu, mu)**2\n",
    "print(\"Analytic correction factor:\\n \" + str(cFactorAnalytic))\n",
    "###----numeric cFactor ----###\n",
    "nsig = 5 # how far I measure to the sides\n",
    "x_like = np.linspace(-nsig*sig,nsig*sig, nsig*points_per_sig)\n",
    "Xvec, Yvec = np.array(np.meshgrid(x_like,x_like))\n",
    "\n",
    "\n",
    "gaussStd = gaussian(Xvec, sig, mu)*gaussian(Yvec, sig, mu)\n",
    "\n",
    "\n",
    "n_steps = 11\n",
    "binning_steps=np.zeros(n_steps, dtype=int)\n",
    "\n",
    "for i in range(n_steps):\n",
    "    binning_steps[i] = 2**i\n",
    "#print(binning_steps)\n",
    "\n",
    "#first without added noise\n",
    "print(\"Correction Factor numeric, no noise:\")\n",
    "noNoiseGaussCorrection = np.zeros(len(binning_steps))\n",
    "for ind in range(len(binning_steps)):\n",
    "    gaussBinned = binMap(gaussStd, binning_steps[ind])\n",
    "    #pump = np.ones(np.shape(gaussBinned))\n",
    "    pump = gaussBinned\n",
    "    probe = gaussBinned\n",
    "    denominator = np.sum(np.multiply(pump, probe)[:])\n",
    "    constantPumpIntensity = np.max(pump)\n",
    "    enumerator = np.sum(constantPumpIntensity*probe[:])\n",
    "    #this is missing various constant factors, since this is not using the gaussian shape, but is discretized\n",
    "    noNoiseGaussCorrection[ind] = enumerator/denominator\n",
    "    print(\"binning = 1/\"+str(binning_steps[ind])+\": \" + str(noNoiseGaussCorrection[ind]))\n",
    "\n",
    "plt.figure(dpi = 200, figsize=(8,4))\n",
    "plt.plot(np.linspace(n_steps-1,0,n_steps), noNoiseGaussCorrection, label = \"no noise\")\n",
    "#with added noise\n",
    "Noiselevels = [0.05,0.1,0.2]\n",
    "NoiseGaussCorrection = np.zeros((len(Noiselevels), len(binning_steps)))\n",
    "for indexSNR, SNR in enumerate(Noiselevels):\n",
    "\n",
    "    gauss1 = gaussStd + (np.random.rand(np.shape(gauss1)[0], np.shape(gauss1)[1])-0.5)*np.max(gauss1)*SNR\n",
    "    gauss2 = gaussStd + (np.random.rand(np.shape(gauss2)[0], np.shape(gauss2)[1])-0.5)*np.max(gauss2)*SNR\n",
    "    \n",
    "    for ind in range(len(binning_steps)):\n",
    "        pump = binMap(gauss1, binning_steps[ind])\n",
    "        probe = binMap(gauss2, binning_steps[ind])\n",
    "        denominator = np.sum(np.multiply(pump, probe)[:])\n",
    "        constantPumpIntensity = np.max(pump)\n",
    "        enumerator = np.sum(constantPumpIntensity*probe[:])\n",
    "        #this is missing various constant factors, since this is not using the gaussian shape, but is discretized\n",
    "        NoiseGaussCorrection[indexSNR, ind] = enumerator/denominator\n",
    "    plt.plot(np.linspace(n_steps-1,0,n_steps), NoiseGaussCorrection[indexSNR], label = \"SNR = %.2f dB\" %(10*np.log10(1/SNR)), linestyle='dashed')\n",
    "\n",
    "\n",
    "\n",
    "plt.plot([0,n_steps-1], [2,2], label=\"analytical correction\", linestyle=\"dotted\", color = 'red')\n",
    "plt.xlabel(\"log2 of discrete point density per sig\")\n",
    "plt.ylabel(\"Correction factor\")\n",
    "plt.ylim([1,3])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test binning of numerical correction factor\n",
    "#Testing how the offset actually behaves\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "def gaussian(x, sig = 1, mu = 0):\n",
    "    return 1/(np.sqrt(2*np.pi)*sig)*np.exp(-(x-mu)**2/(2*sig**2))\n",
    "\n",
    "def cFactor(sigPump, sig2, mu1, mu2):\n",
    "    return np.sqrt((sigPump**2 + sig2**2)/sigPump**2)*np.exp((mu1-mu2)**2/(2*(sigPump**2+sig2**2)))\n",
    "\n",
    "def binMap(map, xBinning, yBinning=0):\n",
    "    '''N_binning means that N*N pixels are binned together\\n\n",
    "    only takes square z*z maps'''\n",
    "    if yBinning == 0:\n",
    "        yBinning = xBinning\n",
    "    xBins = int(np.shape(map)[0]//xBinning) #along one axis\n",
    "    yBins = int(np.shape(map)[1]//yBinning) #along one axis\n",
    "    outmap = map.reshape(xBins, xBinning, yBins, yBinning).sum(3).sum(1)\n",
    "    return outmap\n",
    "\n",
    "\n",
    "#using identical gaussians for this\n",
    "points_per_sig = 1024 #starting value 1000 points for 1 sig distance\n",
    "sig = 1 #does not matter since I do binning in steps of sig at first\n",
    "dmu = 1\n",
    "###----analytical cFactor ----###\n",
    "cFactorAnalytic = cFactor(sig, sig, dmu/2, -dmu/2)**2\n",
    "print(\"Analytic correction factor:\\n \" + str(cFactorAnalytic))\n",
    "###----numeric cFactor ----###\n",
    "nsig = 5 # how far I measure to the sides\n",
    "x_like = np.linspace(-nsig*sig,nsig*sig, nsig*points_per_sig)\n",
    "Xvec, Yvec = np.array(np.meshgrid(x_like,x_like))\n",
    "\n",
    "\n",
    "n_steps = 11\n",
    "binning_steps=np.zeros(n_steps, dtype=int)\n",
    "for i in range(n_steps):\n",
    "    binning_steps[i] = 2**i\n",
    "\n",
    "d_offset = [0,0.1,0.2,0.5]\n",
    "GaussCorrection = np.zeros((len(d_offset),len(binning_steps)))\n",
    "for indOffset, offset in enumerate(d_offset):\n",
    "\n",
    "    gauss1 = gaussian(Xvec, sig, +dmu/2+offset)*gaussian(Yvec, sig, +dmu/2)\n",
    "    gauss2 = gaussian(Xvec, sig, -dmu/2+offset)*gaussian(Yvec, sig, -dmu/2)\n",
    "\n",
    "\n",
    "    for ind in range(len(binning_steps)):\n",
    "        pump = binMap(gauss1, binning_steps[ind])\n",
    "        probe = binMap(gauss2, binning_steps[ind])\n",
    "        denominator = np.sum(np.multiply(pump, probe)[:])\n",
    "        constantPumpIntensity = np.max(pump)\n",
    "        enumerator = np.sum(constantPumpIntensity*probe[:])\n",
    "        #this is missing various constant factors, since this is not using the gaussian shape, but is discretized\n",
    "        GaussCorrection[indOffset, ind] = enumerator/denominator\n",
    "\n",
    "\n",
    "plt.figure(dpi = 200, figsize=(8,4))\n",
    "for i in range(len(d_offset)):\n",
    "    plt.plot(np.linspace(n_steps-1,0,n_steps), GaussCorrection[i], label = \"%.1f \\sigma\" %d_offset[i])\n",
    "plt.plot([0,n_steps-1], [cFactorAnalytic,cFactorAnalytic], label=\"analytical correction\", linestyle=\"dotted\", color = 'red')\n",
    "plt.xlabel(\"log2 of discrete point density per sig\")\n",
    "plt.ylabel(\"Correction factor\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import constants as const\n",
    "import numpy as np\n",
    "plt.rcParams['text.usetex'] = True\n",
    "font = {'size': 20}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "umPerPx = 6.949\n",
    "dumPerPx = 4E-2\n",
    "dRelUmPerPx = dumPerPx/umPerPx\n",
    "\n",
    "def wavToEnergy(lamb):\n",
    "    #Energy in eV, lamb in nm\n",
    "    return const.h*const.c/lamb*1e9/const.elementary_charge\n",
    "\n",
    "def energyToWav(E):\n",
    "    #Energy in eV, lamb in nm\n",
    "    return const.h*const.c/E*1e9/const.elementary_charge\n",
    "\n",
    "def paramDictatTime(param_dict, time_fs):\n",
    "    return param_dict['A1']*np.exp(-time_fs/param_dict['tau1']) + param_dict['A2']*np.exp(-time_fs/param_dict['tau2'])\n",
    "#import data from excel (terrible choice I know, but I want the visualisation and comparability)\n",
    "\n",
    "def ErrorCorrectionConvoluted(signal, correctionFactor, peakRadiance, dRelUmPerPx, dRelPower):\n",
    "    '''correctionfactor is already divided with peak radiance\\\\\n",
    "    dRelPower = dPower/Power'''\n",
    "    dPeakRadiance = dRelPower*peakRadiance + 2*peakRadiance*dRelUmPerPx\n",
    "    return abs(signal*correctionFactor/peakRadiance*dPeakRadiance)\n",
    "\n",
    "SHG_main = pd.read_excel(\"CorrectedPump653ProbeWavelengthScan_UV-extended.xlsx\", sheet_name='2024WavelengthScan', skiprows=[0,1])\n",
    "#print(SHG_main)\n",
    "print(SHG_main.keys())\n",
    "\n",
    "wavelengths = SHG_main['Probe wavelength / nm']\n",
    "#simple correction without map\n",
    "dOD_SHG_main = SHG_main['cor_dOD / (mOD*m^2/W)']\n",
    "#correction with map\n",
    "dOD_SHG_mapCorr = SHG_main['hypothetical correction']\n",
    "dPumpPower = SHG_main['dRelPumpPower']\n",
    "peakRad = SHG_main['Pump power density / (W/m^2)']\n",
    "\n",
    "\n",
    "\n",
    "SHG_wav_timescan = pd.read_excel(\"CorrectedPump653ProbeWavelengthScan_UV-extended.xlsx\", sheet_name = \"2024WavelengthScanParameters\", skiprows=[0,1])\n",
    "scan_wavs = SHG_wav_timescan['Probe wavelength / nm']\n",
    "scan_corrFactors = SHG_wav_timescan['Correction Factor / (W/m^2)^-1']\n",
    "scan_params = {\n",
    "    'A1' : SHG_wav_timescan['A1'],\n",
    "    'A2' : SHG_wav_timescan['A2'],\n",
    "    'tau1' : SHG_wav_timescan['tau1'],\n",
    "    'tau2' : SHG_wav_timescan['tau2'],\n",
    "}\n",
    "\n",
    "times = np.array([1e2, 1e4, 2e4, 2e5])\n",
    "\n",
    "print(ErrorCorrectionConvoluted(dOD_SHG_main, scan_corrFactors, peakRad, dRelUmPerPx, dPumpPower))\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(8,4), dpi = 200)\n",
    "''''''\n",
    "ax.plot(wavelengths, dOD_SHG_main, 'ro', label='standard correction', ls = \"None\")\n",
    "ax.plot(wavelengths, dOD_SHG_mapCorr, 'bx', label='map corrected', ls = \"None\")\n",
    "ax.errorbar(wavelengths, dOD_SHG_main, yerr = ErrorCorrectionConvoluted(dOD_SHG_main, scan_corrFactors, peakRad, dRelUmPerPx, dPumpPower), ls = \"None\", capsize =2)\n",
    "'''\n",
    "for ind, time in enumerate(times):\n",
    "    ax.plot(scan_wavs, paramDictatTime(scan_params, time), '.', label=time)\n",
    "'''\n",
    "ax.set_xlabel('probe wavelength / nm')\n",
    "ax.set_ylabel(r'$\\mathrm{absorbance / mOD\\cdot \\frac{m^2}{W}}$')\n",
    "\n",
    "ax.set_xticks(np.arange(300, 701, 50))\n",
    "secax = ax.secondary_xaxis('top', functions=(wavToEnergy, energyToWav))\n",
    "secax.set_xticks(np.round(wavToEnergy(np.array([440, 500, 653])), 2))\n",
    "secax.set_xlabel(r\"$\\mathrm{E_{probe} / eV}$\")\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### peak radiance variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import constants as const\n",
    "from scipy import io\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "plt.rcParams['text.usetex'] = True\n",
    "font = {'size': 20}\n",
    "plt.rc('font', **font)\n",
    "#From 2023.12.22 PumpPowerVar in pump 653 Probe 680\n",
    "#2nd-x;170.98460380387596;4.882207633023595;1.0;0.0;3.5228\n",
    "#2nd-x Error;0.044586461622659335;0.10565856496080137;60.88881374774401;1.876611874015875;3.5228\n",
    "#2nd-y;123.76193757659699;5.398671742339542;1.0;0.0;3.5228\n",
    "#2nd-y Error;0.007988920725724555;0.018944810621290376;10.67173147785706;0.31277821947196766;3.5228\n",
    "\n",
    "file = open(r\"c:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\STD-680\\2023.12.22_PumpPowerVar\\TAfitPump653Probe680_OUTPUT.JSON\")\n",
    "entries = json.load(file)['entries']\n",
    "entries_files = []\n",
    "dOD = []\n",
    "for entry in entries:\n",
    "    entries_files.append(entry['inputFile'])\n",
    "    dOD.append([entry['popt'][2], entry['pcov'][2][2]])\n",
    "\n",
    "dOD = np.array(dOD)\n",
    "dOD[dOD == np.inf] = np.NaN\n",
    "#print(dOD)\n",
    "#these are in order\n",
    "pumpRad = np.array([[620, 43], [620, 43], [620, 43], [3250, 30], [4430,30], [5900, 30], [4430, 30], [4430, 30], [4430, 30]])\n",
    "probeRad = np.array([[910, 100], [1820, 60], [460, 100], [460, 100], [460, 100], [460, 100], [910, 60], [3640, 20], [1820, 30]])\n",
    "\n",
    "\n",
    "#try calculating a fun correction factor based on the first 3 measurements that have identical pump radiance\n",
    "#need to take the times such as done in degradation\n",
    "io.loadmat(r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\STD-680\\2023.12.22_PumpPowerVar\\saturation_2023-12-22_11-47.mat\")\n",
    "\n",
    "linParameter = np.polyfit(pumpRad[:3,0], dOD[:3,0], 1)\n",
    "\n",
    "#print(pumpRad[])\n",
    "#Plot first 6 points as they should have relatively little sample degradation, because of their order and the pump power\n",
    "fig, ax = plt.subplots(1,2, figsize=(12,4), dpi = 200)\n",
    "ax[0].plot(pumpRad[:6,0], dOD[:6,0], 'b.')\n",
    "#yerror of dOD fitting is not sensible\n",
    "ax[0].errorbar(pumpRad[:6,0], dOD[:6,0], xerr = pumpRad[:6,1], ls = \"None\", ecolor = 'b', capsize = 2)\n",
    "ax[0].set_xlabel('pump peak radiance / W per m\\^2')\n",
    "ax[0].set_ylabel('absorbance / mOD')\n",
    "ax[1].plot(probeRad[6:,0], dOD[6:,0], 'r')\n",
    "ax[1].errorbar(probeRad[6:,0], dOD[6:,0], xerr = probeRad[6:,1], ls=\"None\", ecolor = \"r\", capsize = 2)\n",
    "ax[1].set_xlabel('probe peak radiance / W per m\\^2')\n",
    "fig.suptitle('no degradation correction yet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import constants as const\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import json\n",
    "\n",
    "\n",
    "plt.rcParams['text.usetex'] = True\n",
    "font = {'size': 20}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "def parseTime(time):\n",
    "    '''takes time in hh:mm:ss and returns a value in s'''\n",
    "    times = np.zeros(len(time), dtype = int)\n",
    "    hh, mm, ss = str(time[0]).split(\":\")\n",
    "    times[0] = int(hh)*3600+int(mm)*60+int(ss)\n",
    "    for i in range(len(time)-1):\n",
    "        hh, mm, ss = str(time[i+1]).split(\":\")\n",
    "        times[i+1] = int(hh)*3600+int(mm)*60+int(ss) - times[0]\n",
    "\n",
    "    times[0] = 0\n",
    "    return times\n",
    "\n",
    "def getTimes(filepath):\n",
    "    '''moved out of degradationCompensation for general use'''\n",
    "    tempLoad = io.loadmat(filepath)\n",
    "    #test if file has keys for single TA measurement\n",
    "\n",
    "    if 'delay' in tempLoad.keys() and 'd_vec' in tempLoad.keys():\n",
    "        #this part can easily be broken by a matlab update\n",
    "        #load time\n",
    "        timeString = str(tempLoad['__header__']).split(\"Created on: \")[1]\n",
    "        timeString = timeString.split(' ')[3]\n",
    "        #print(timeString)\n",
    "        subTimes = np.zeros((1,3), dtype=float)\n",
    "        subTimes[:] = timeString.split(':')[:3]\n",
    "\n",
    "    elif 'dates' in tempLoad.keys():\n",
    "        subDates = tempLoad['dates'][0]\n",
    "        subTimes = np.zeros((len(subDates), 3), dtype=float)\n",
    "        for ind, timeArray in enumerate(subDates):\n",
    "            #print(timeArray[0][3:6])\n",
    "            timeArray = timeArray[0][3:6]\n",
    "            #print(timeArray)\n",
    "            subTimes[ind,0] = timeArray[0]#hh\n",
    "            subTimes[ind,1] = timeArray[1]##mm\n",
    "            subTimes[ind,2] = timeArray[2]##ss with miliseconds\n",
    "    return subTimes\n",
    "    \n",
    "def degradationCompensation(degradePerSecond, filepathArray, powerDensities):\n",
    "    '''returns correction factor for each measurement\\\\\n",
    "        degradePerSecond is a linear fit of degradation per second per W/m^2 peak\\\\\n",
    "        filepathArray is ordered array of measurements after each other\\\\\n",
    "        powerdensities is either a single number (int/float) or array of powerdensities of size of filepathArray\\\\\n",
    "        not optimal but a linear approximation is about as good as I can do it with the data available'''\n",
    "    from scipy import io \n",
    "    timesInSecond = np.zeros(len(filepathArray))\n",
    "    AllTimes = [] #list so I can append\n",
    "    for path in filepathArray:\n",
    "        #need to differentiate between the summary of TA scans and TA scans\n",
    "        #do not mix and match please\n",
    "        #try:\n",
    "        AllTimes.append(getTimes(path))\n",
    "    \n",
    "\n",
    "\n",
    "        #except: \n",
    "        #    print(\"dooters\")\n",
    "    #print(AllTimes)\n",
    "    timesFromZero = np.zeros(np.shape(AllTimes)[:2])\n",
    "    degradationCorrection = np.zeros(np.shape(AllTimes)[:2])\n",
    "\n",
    "    #grab the zero time\n",
    "    zeroTime = np.array(AllTimes[0][0])\n",
    "    \n",
    "    if type(powerDensities) != type(np.ndarray):\n",
    "        powerDensities = np.ones(np.shape(AllTimes)[0])\n",
    "        \n",
    "\n",
    "    for ind in range(np.shape(AllTimes)[0]):\n",
    "        for subindex in range(np.shape(AllTimes[ind])[0]):\n",
    "            #hours\n",
    "            timesFromZero[ind,subindex] = (AllTimes[ind][subindex][0]-zeroTime[0])*3600\n",
    "            #check for day-tickover\n",
    "            if timesFromZero[ind,subindex] < 0:\n",
    "                timesFromZero[ind,subindex] += 24*3600\n",
    "            #minutes\n",
    "            timesFromZero[ind,subindex] += (AllTimes[ind][subindex][1]-zeroTime[1])*60\n",
    "            #seconds\n",
    "            timesFromZero[ind,subindex] += AllTimes[ind][subindex][2]-zeroTime[2]\n",
    "            degradationCorrection[ind, subindex] = 1/(1-degradePerSecond*timesFromZero[ind,subindex]*powerDensities[ind])\n",
    "        \n",
    "    return degradationCorrection, timesFromZero\n",
    "\n",
    "\n",
    "testArray = [r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\Pump653Probe493_Degradation\\TA_fourier_6778.mat\", \n",
    "             r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\Pump653Probe493_Degradation\\TA_fourier_6779.mat\"]\n",
    "#degradationCompensation(1, [r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\Pump653Probe493_Degradation\\saturation_2024-01-19_16-14.mat\"], 1)\n",
    "#degradationCompensation(1, testArray, 1)\n",
    "\n",
    "#to be tested yet\n",
    "#refits of this are useless so far...\n",
    "\n",
    "powerVar = pd.read_excel(\"CorrectedPump653ProbeWavelengthScan_UV-extended.xlsx\", sheet_name='Degradation493nm')\n",
    "dtime = parseTime(powerVar['time'])\n",
    "\n",
    "#dOD = powerVar['dOD / mOD']\n",
    "\n",
    "\n",
    "file = open(r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\Pump653Probe493_Degradation\\TAfitPump653Probe493_OUTPUT.JSON\")\n",
    "entries = json.load(file)['entries']\n",
    "entries_files = []\n",
    "timeAt = np.array([0,1e3,5e3]) #fs\n",
    "dOD = np.zeros((len(entries), len(timeAt)))\n",
    "expDecay = lambda ampTau1, ampTau2, t: ampTau1[0]*np.exp(-t/ampTau1[1])+ampTau2[0]*np.exp(-t/ampTau2[1])\n",
    "\n",
    "for ind, entry in enumerate(entries):\n",
    "    entries_files.append(entry['inputFile'])\n",
    "    for indTime, time in enumerate(timeAt):\n",
    "        dOD[ind,indTime] = expDecay(entry['popt'][2:4], entry['popt'][4:6], time)\n",
    "\n",
    "\n",
    "dOD = np.array(dOD)\n",
    "dOD[dOD == np.inf] = np.NaN\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(8,4), dpi = 200)\n",
    "for i in range(len(timeAt)):\n",
    "    ax.plot(dtime, dOD[:,i], label=\"delay = %.1e fs\" %timeAt[i])\n",
    "ax.legend()\n",
    "ax.set_xlabel('time / s')\n",
    "ax.set_ylabel('absorbance / mOD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SeriesDegradation\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['text.usetex'] = True\n",
    "font = {'size': 12}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "start = 6778\n",
    "stop = 6787\n",
    "dirPath = r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\Pump653Probe493_Degradation\\\\\"\n",
    "SeriesDegradation.plotTrend(dirPath, start, stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correction value check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import constants as const\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import sys\n",
    "import json\n",
    "sys.path.insert(1, r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\")\n",
    "from peakRadianceAuto import autoPeakRadiance\n",
    "from ArtrayAnalysis import ArtFit\n",
    "\n",
    "def correctionFactorWithError(pathJSON, fittingPath):\n",
    "    '''Returns correction factor with uncertainty in dOD per W/m^2\\\\\n",
    "        pathJSON is to summary\\\\\n",
    "            fittingPath is to standard fit.txt (2 beam pointspreads supported)'''\n",
    "    #don't care about loading these multiple times\n",
    "    #returns first \n",
    "    peakRad, dPeakRad = autoPeakRadiance(pathJSON, fittingPath)\n",
    "    #only choose pump\n",
    "    peakRad = peakRad[1]\n",
    "    dPeakRad = dPeakRad[1]\n",
    "    #dict with {\"pump/probe\": {\"x/y\" : [[sig, error],...]}}\n",
    "    dataDict = ArtFit.parseFitFile(fittingPath)\n",
    "\n",
    "    pump = dataDict[\"pump\"]\n",
    "    probe = dataDict[\"probe\"]\n",
    "    #coeffs = x_center, sig, Amplitude, offset\n",
    "    #sig1Error = lambda corr, sig1, sig2, muDiff, dsig1 : dsig1*corr*(sig1**3/sig2**2+sig1+muDiff**2*sig1/(sig1**2+sig2**2)**2)\n",
    "    #sig2Error = lambda corr, sig1, sig2, muDiff, dsig2: dsig2*corr*((sig1**2+sig2**2)/sig2 + muDiff**2*sig2/(sig1**2+sig2**2)**2)\n",
    "    #muDiffError = lambda corr, sig1, sig2, muDiff, dmuDiff: dmuDiff*corr*muDiff/(sig1**2+sig2**2)\n",
    "\n",
    "    sig1Error = lambda corr, coeffs1, coeffs2: coeffs1[1,1]*corr*(coeffs1[1,0]**3/coeffs2[1,0]**2+coeffs1[1,0]+(coeffs1[0,0]-coeffs2[0,0])**2*coeffs1[1,0]/(coeffs1[1,0]**2+coeffs2[1,0]**2)**2)\n",
    "    sig2Error = lambda corr, coeffs1, coeffs2: coeffs2[1,1]*corr*((coeffs1[1,0]**2+coeffs2[1,0]**2)/coeffs2[1,0]+ (coeffs1[0,0]-coeffs2[0,0])**2*coeffs2[1,0]/(coeffs1[1,0]**2+coeffs2[1,0]**2)**2)\n",
    "    #using compound error for this one\n",
    "    muDiffError = lambda corr, coeffs1, coeffs2: (coeffs1[0,1]+coeffs2[0,1])*corr*(coeffs1[0,0]-coeffs2[0,0])/(coeffs1[1,0]**2+coeffs2[1,0]**2)\n",
    "    #simplification\n",
    "    fullError = lambda corr, coeffs1, coeffs2: sig1Error(corr, coeffs1, coeffs2) + sig2Error(corr, coeffs1, coeffs2) + muDiffError(corr, coeffs1, coeffs2)\n",
    "    #takes pump then probe\n",
    "    xCorr = ArtFit.calculateOverlapCorrection(pump[\"x\"][:,0], probe[\"x\"][:,0], 5)\n",
    "    dXCorr = fullError(xCorr, pump['x'], probe['x'])\n",
    "    yCorr = ArtFit.calculateOverlapCorrection(pump[\"y\"][:,0], probe[\"y\"][:,0], 5)\n",
    "    dYCorr = fullError(xCorr, pump['y'], probe['y'])\n",
    "    totalCorr = xCorr*yCorr/peakRad\n",
    "    totalError = (xCorr*dYCorr+yCorr*dXCorr)/peakRad + totalCorr*dPeakRad/peakRad**2\n",
    "    #print(totalCorr)\n",
    "    #print(totalError)\n",
    "    sigCalc = lambda probeCoeff, pumpCoeff: [probeCoeff[1,0]/pumpCoeff[1,0], probeCoeff[1,1]/pumpCoeff[1,0] + probeCoeff[1,0]/pumpCoeff[1,0]**2*pumpCoeff[1,1]]\n",
    "    sigbysig = np.array([sigCalc(probe['x'], pump['x']), sigCalc(probe['y'], pump['y'])], dtype = float)\n",
    "    dmu = np.array([[abs(probe[\"x\"][0,0]-pump[\"x\"][0,0]), probe[\"x\"][0,1]+pump[\"x\"][0,1]],[abs(probe[\"y\"][0,0]-pump[\"y\"][0,0]), probe[\"y\"][0,1]+pump[\"y\"][0,1]]], dtype = float)\n",
    "    return [totalCorr, totalError], sigbysig, dmu\n",
    "\n",
    "\n",
    "\n",
    "file = open(r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\Pump653Probe493_ArtrayCompensationControl\\TAfitPump653Probe493_OUTPUT.JSON\")\n",
    "entries = json.load(file)['entries']\n",
    "entries_files = []\n",
    "dOD = []\n",
    "for entry in entries:\n",
    "    entries_files.append(entry['inputFile'])\n",
    "    dOD.append([entry['popt'][2]+ entry['popt'][4], entry['pcov'][2][2]+entry['pcov'][4][2]])\n",
    "\n",
    "dOD = np.array(dOD)\n",
    "dOD[dOD == np.inf] = np.NaN\n",
    "\n",
    "basepath = lambda filename: r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\Pump653Probe493_ArtrayCompensationControl\" + filename\n",
    "inputFiles = [(r\"\\SummaryPump653Probe493Caution.JSON\", r\"\\BeamFitsPump653Probe493Caution.txt\"),\n",
    "              (r\"\\SummaryPump653Probe493_ShiftedProbe.JSON\", r\"\\BeamFitsPump653Probe493_ShiftedProbe.txt\"),\n",
    "              (r\"\\SummaryPump653Probe493_WideProbe.JSON\", r\"\\BeamFitsPump653Probe493_WideProbe.txt\"),\n",
    "              (r\"\\SummaryPump653Probe493_ThinProbe.JSON\", r\"\\BeamFitsPump653Probe493_ThinProbe.txt\")]\n",
    "labels = [\"standard\", \"shifted\", \"wide probe\", \"thin probe\"]\n",
    "correctionFactors = np.zeros((4,2))\n",
    "dmu = np.zeros((4,2,2))\n",
    "sigbysig = np.zeros((4,2,2))\n",
    "\n",
    "for index, shortPath in enumerate(inputFiles):\n",
    "    correctionFactors[index,:], sigbysig[index], dmu[index] = correctionFactorWithError(basepath(shortPath[0]), basepath(shortPath[1]))\n",
    "    print(\"xsigRatio: %.3e +- %.3e, xdmu: %.3e +- %.3e\" %(sigbysig[index, 0,0], sigbysig[index, 0,1], dmu[index, 0,0], dmu[index, 0,1]))\n",
    "    print(\"ysigRatio: %.3e +- %.3e, ydmu: %.3e +- %.3e\" %(sigbysig[index,1,0], sigbysig[index,1,1], dmu[index,1,0], dmu[index,1,1]))\n",
    "    print(\"%s: %.3e +- %.3e dOD per W/msquare\" %(labels[index], correctionFactors[index,0]*dOD[index, 0], correctionFactors[index,1]*dOD[index, 0]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
